# FORMAT
# Put your extra requirements here in the following format
#
# package[version_required]	: tag1, tag2, ...
# ex) pip install -e .\[modin\]

fugashi					: tokenize, fugashi
mecab-python3           : tokenize, mecab
mecab-ko-dic			: tokenize, mecab
pysbd					: tokenize, dataset
pynori					: tokenize, pynori
soynlp					: tokenize, soynlp
nltk					: tokenize, nltk
sacremoses				: tokenize
emoji					: tokenize, dataset
# sentencepiece			: tokenize

tomotopy			  	: topic
wordcloud				: topic
pyLDAvis				: topic

pyhwp					: parser, hwp, bok
wikiextractor			: parser, wiki
namu-wiki-extractor		: parser, wiki
pdfplumber				: parser, fomc
mail-parser				: parser, mail
pubmed_parser			: parser, pubmed
jsonpath-ng				: parser, dataset
beautifulsoup4			: parser, dataset
html-to-json			: parser, html
fasttext-langdetect		: parser, langdetect
cssutils                : parser, edgar

simpletransformers		: transformers, model
datasets				: transformers, dataset, model
# torch					: transformers
tensorflow				: transformers, model
# tf-nightly 				: transformers, model
google-api-python-client	: transformers, model

modin					: pandas
ray						: pandas
# dask					: pandas
# swifter					: pandas

# sysrsync				: fetch
wget					: fetch
py7zr					: fetch
zstandard				: fetch

pymongo					: database

# py-markdown-table		: doc
# pytablewriter			: doc
plotly					: doc, visualize
kaleido					: doc, visualize
rich					: doc, visualize
matplotlib				: doc, visualize
seaborn                 : doc, visualize

tensorflow-datasets		: dataset
# tensorflow-io			: dataset
lsh 					: dataset
orjson 					: dataset, parser
datasketch 				: dataset
pysimdjson				: dataset, parser
p_tqdm					: dataset, parser
joblib					: dataset, parser
ftfy					: dataset, parser, tokenize
jsonlines				: dataset, parser
loky					: dataset, parser
pathos                    : dataset, parser, edgar
# guesslang 				: dataset, parser

numba                   : numba
